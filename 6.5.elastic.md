# Домашнее задание к занятию "6.5. Elasticsearch"

## Задача 1
<details>
	<summary></summary>
      <br>

В этом задании вы потренируетесь в:
- установке elasticsearch
- первоначальном конфигурировании elastcisearch
- запуске elasticsearch в docker

Используя докер образ [elasticsearch:7](https://hub.docker.com/_/elasticsearch) как базовый:

- составьте Dockerfile-манифест для elasticsearch
- соберите docker-образ и сделайте `push` в ваш docker.io репозиторий
- запустите контейнер из получившегося образа и выполните запрос пути `/` c хост-машины

Требования к `elasticsearch.yml`:
- данные `path` должны сохраняться в `/var/lib` 
- имя ноды должно быть `netology_test`

В ответе приведите:
- текст Dockerfile манифеста
- ссылку на образ в репозитории dockerhub
- ответ `elasticsearch` на запрос пути `/` в json виде

Подсказки:
- при сетевых проблемах внимательно изучите кластерные и сетевые настройки в elasticsearch.yml
- при некоторых проблемах вам поможет docker директива ulimit
- elasticsearch в логах обычно описывает проблему и пути ее решения
- обратите внимание на настройки безопасности такие как `xpack.security.enabled` 
- если докер образ не запускается и падает с ошибкой 137 в этом случае может помочь настройка `-e ES_HEAP_SIZE`
- при настройке `path` возможно потребуется настройка прав доступа на директорию

Далее мы будем работать с данным экземпляром elasticsearch.
</details>

### ОТВЕТ:

```
Dockerfile
_______________________________________________
FROM centos:7

RUN yum install wget -y && \
    yum install perl-Digest-SHA -y

ENV ES_DIR="/opt/elasticsearch"
ENV ES_HOME="${ES_DIR}/elasticsearch-7.16.0"

WORKDIR ${ES_DIR}

RUN wget --quiet https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.16.0-linux-x86_64.tar.gz && \
    wget --quiet https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.16.0-linux-x86_64.tar.gz.sha512 && \
    sha512sum --check --quiet elasticsearch-7.16.0-linux-x86_64.tar.gz.sha512 && \
    tar -xzf elasticsearch-7.16.0-linux-x86_64.tar.gz

COPY elasticsearch.yml ${ES_HOME}/config

ENV ES_USER="elasticsearch"

RUN useradd ${ES_USER}

RUN mkdir -p "/var/lib/elasticsearch" && \
    mkdir -p "/var/log/elasticsearch"

RUN chown -R ${ES_USER}: "${ES_DIR}" && \
    chown -R ${ES_USER}: "/var/lib/elasticsearch" && \
    chown -R ${ES_USER}: "/var/log/elasticsearch"

USER ${ES_USER}

WORKDIR "${ES_HOME}"

EXPOSE 9200
EXPOSE 9300

ENTRYPOINT ["./bin/elasticsearch"]
_______________________________________________

elasticsearch.yml
_______________________________________________
discovery:
  type: single-node

cluster:
  name: netology

node:
  name: netology_test

network:
  host: 0.0.0.0

path:
  data: /var/lib/elasticsearch
  logs: /var/log/elasticsearch
_______________________________________________

root@ubuntu-virtual:/home/user# docker build -t alextupicyn/test:elasticsearch .
...
root@ubuntu-virtual:/home/user# docker login -u "alextupicyn" -p "******" docker.io
...
root@ubuntu-virtual:/home/user# docker push alextupicyn/test:elasticsearch
...
root@ubuntu-virtual:/home/user# docker image ls
REPOSITORY         TAG             IMAGE ID       CREATED         SIZE
alextupicyn/test   elasticsearch   80d71ab35781   6 hours ago     2.21GB
centos             7               eeb6ee3f44bd   10 months ago   204MB

root@ubuntu-virtual:/home/user# docker run --rm -d --name elastic -p 9200:9200 -p 9300:9300 alextupicyn/test:elasticsearch

root@ubuntu-virtual:/home/user# docker exec -it elastic bash

[elasticsearch@47fa8963f7d4 elasticsearch-7.16.0]$ curl localhost:9200
{
  "name" : "netology_test",
  "cluster_name" : "netology",
  "cluster_uuid" : "CWRaVpbuRqWX1SXy3pOfFA",
  "version" : {
    "number" : "7.16.0",
    "build_flavor" : "default",
    "build_type" : "tar",
    "build_hash" : "6fc81662312141fe7691d7c1c91b8658ac17aa0d",
    "build_date" : "2021-12-02T15:46:35.697268109Z",
    "build_snapshot" : false,
    "lucene_version" : "8.10.1",
    "minimum_wire_compatibility_version" : "6.8.0",
    "minimum_index_compatibility_version" : "6.0.0-beta1"
  },
  "tagline" : "You Know, for Search"
}
```
докер образ [elasticsearch](https://hub.docker.com/r/alextupicyn/test/tags)


## Задача 2
<details>
	<summary></summary>
      <br>

В этом задании вы научитесь:
- создавать и удалять индексы
- изучать состояние кластера
- обосновывать причину деградации доступности данных

Ознакомтесь с [документацией](https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-create-index.html) 
и добавьте в `elasticsearch` 3 индекса, в соответствии со таблицей:

| Имя | Количество реплик | Количество шард |
|-----|-------------------|-----------------|
| ind-1| 0 | 1 |
| ind-2 | 1 | 2 |
| ind-3 | 2 | 4 |

Получите список индексов и их статусов, используя API и **приведите в ответе** на задание.

Получите состояние кластера `elasticsearch`, используя API.

Как вы думаете, почему часть индексов и кластер находится в состоянии yellow?

Удалите все индексы.

**Важно**

При проектировании кластера elasticsearch нужно корректно рассчитывать количество реплик и шард,
иначе возможна потеря данных индексов, вплоть до полной, при деградации системы.
</details>

### ОТВЕТ:

```
[elasticsearch@55c1e4cf4b34 elasticsearch-7.16.0]$ curl -X PUT "localhost:9200/ind-1?pretty" -H 'Content-Type: application/json' -d' { "settings": { "number_of_shards": 1, "number_of_replicas": 0 }}'

[elasticsearch@55c1e4cf4b34 elasticsearch-7.16.0]$ curl -X PUT localhost:9200/ind-2 -H 'Content-Type: application/json' -d'{ "settings": { "number_of_shards": 2,  "number_of_replicas": 1 }}'

[elasticsearch@55c1e4cf4b34 elasticsearch-7.16.0]$ curl -X PUT localhost:9200/ind-3 -H 'Content-Type: application/json' -d'{ "settings": { "number_of_shards": 4,  "number_of_replicas": 2 }}'

[elasticsearch@55c1e4cf4b34 elasticsearch-7.16.0]$ curl -X GET 'http://localhost:9200/_cat/indices?v'
health status index            uuid                   pri rep docs.count docs.deleted store.size pri.store.size
green  open   .geoip_databases r0ei1Yn9RFSVAbNbkNcjTQ   1   0         40            0     37.7mb         37.7mb
green  open   ind-1            Re5HC8MXSN6xsqu-8FKi7w   1   0          0            0       226b           226b
yellow open   ind-3            e1fgWNqgQMa0OvzzcmajCw   4   2          0            0       904b           904b
yellow open   ind-2            GW_wb7t6SniVSXz_9VbuXw   2   1          0            0       452b           452b
[root@6cd503fe970e elasticsearch-7.16.0]# curl -X GET "localhost:9200/_cluster/health?pretty"
{
  "cluster_name" : "netology",
  "status" : "yellow",
  "timed_out" : false,
  "number_of_nodes" : 1,
  "number_of_data_nodes" : 1,
  "active_primary_shards" : 10,
  "active_shards" : 10,
  "relocating_shards" : 0,
  "initializing_shards" : 0,
  "unassigned_shards" : 10,
  "delayed_unassigned_shards" : 0,
  "number_of_pending_tasks" : 0,
  "number_of_in_flight_fetch" : 0,
  "task_max_waiting_in_queue_millis" : 0,
  "active_shards_percent_as_number" : 50.0
}

____________
Первичный шард и реплика не могут находиться на одном узле, если копия не назначена. Таким образом, один узел не может размещать копии
____________

[root@6cd503fe970e elasticsearch-7.16.0]# curl -X DELETE 'http://localhost:9200/_all'
{"acknowledged":true}
[root@6cd503fe970e elasticsearch-7.16.0]# curl -X GET 'http://localhost:9200/_cat/indices?v'
health status index            uuid                   pri rep docs.count docs.deleted store.size pri.store.size
green  open   .geoip_databases r0ei1Yn9RFSVAbNbkNcjTQ   1   0         40            0     37.7mb         37.7mb
```

## Задача 3
<details>
	<summary></summary>
      <br>

В данном задании вы научитесь:
- создавать бэкапы данных
- восстанавливать индексы из бэкапов

Создайте директорию `{путь до корневой директории с elasticsearch в образе}/snapshots`.

Используя API [зарегистрируйте](https://www.elastic.co/guide/en/elasticsearch/reference/current/snapshots-register-repository.html#snapshots-register-repository) 
данную директорию как `snapshot repository` c именем `netology_backup`.

**Приведите в ответе** запрос API и результат вызова API для создания репозитория.

Создайте индекс `test` с 0 реплик и 1 шардом и **приведите в ответе** список индексов.

[Создайте `snapshot`](https://www.elastic.co/guide/en/elasticsearch/reference/current/snapshots-take-snapshot.html) 
состояния кластера `elasticsearch`.

**Приведите в ответе** список файлов в директории со `snapshot`ами.

Удалите индекс `test` и создайте индекс `test-2`. **Приведите в ответе** список индексов.

[Восстановите](https://www.elastic.co/guide/en/elasticsearch/reference/current/snapshots-restore-snapshot.html) состояние
кластера `elasticsearch` из `snapshot`, созданного ранее. 

**Приведите в ответе** запрос к API восстановления и итоговый список индексов.

Подсказки:
- возможно вам понадобится доработать `elasticsearch.yml` в части директивы `path.repo` и перезапустить `elasticsearch`
</details>

### ОТВЕТ:

```
$ docker exec -u root -it elastic bash
[root@6cd503fe970e elasticsearch-7.16.0]# mkdir /opt/backup
[root@6cd503fe970e elasticsearch-7.16.0]# echo path.repo: [ "/opt/backup" ] >> "$ES_HOME/config/elasticsearch.yml"
[root@6cd503fe970e elasticsearch-7.16.0]# chown elasticsearch:elasticsearch /opt/backup

[root@6cd503fe970e elasticsearch-7.16.0]# cat $ES_HOME/config/elasticsearch.yml
discovery:
  type: single-node

cluster:
  name: netology

node:
  name: netology_test

network:
  host: 0.0.0.0

path:
  data: /var/lib/elasticsearch
  logs: /var/log/elasticsearch
path.repo: [ /opt/backup ]
[root@6cd503fe970e elasticsearch-7.16.0]# exit
exit
root@ubuntu-virtual:/home/user/6.5# docker restart elastic
elastic
root@ubuntu-virtual:/home/user/6.5# docker exec -u root -it elastic bash
[root@6cd503fe970e elasticsearch-7.16.0]# curl -X PUT "localhost:9200/_snapshot/netology_backup?pretty" -H 'Content-Type: application/json' -d'
> {
>   "type": "fs",
>   "settings": {
>     "location": "/opt/backup",
>     "compress": true
>   }
> }'
{
  "acknowledged" : true
}

[root@6cd503fe970e elasticsearch-7.16.0]# curl -X PUT "localhost:9200/test?pretty" -H 'Content-Type: application/json' -d'
> {
>   "settings": {
>     "number_of_shards": 1,
>     "number_of_replicas": 0
>   }
> }
> '
{
  "acknowledged" : true,
  "shards_acknowledged" : true,
  "index" : "test"
}

[root@6cd503fe970e elasticsearch-7.16.0]# curl 'localhost:9200/_cat/indices?v'
health status index            uuid                   pri rep docs.count docs.deleted store.size pri.store.size
green  open   .geoip_databases r0ei1Yn9RFSVAbNbkNcjTQ   1   0         40            0     37.7mb         37.7mb
green  open   test             a3hnjvOaQ36LpKdbizblRg   1   0          0            0       226b           226b

[root@6cd503fe970e elasticsearch-7.16.0]# curl -X PUT "localhost:9200/_snapshot/netology_backup/snapshot_1?wait_for_completion=true&pretty"
{
  "snapshot" : {
    "snapshot" : "snapshot_1",
    "uuid" : "CG2LkKlZT_a4cPGFKiXkoA",
    "repository" : "netology_backup",
    "version_id" : 7160099,
    "version" : "7.16.0",
    "indices" : [
      "test",
      ".ds-.logs-deprecation.elasticsearch-default-2022.07.19-000001",
      ".geoip_databases",
      ".ds-ilm-history-5-2022.07.19-000001"
    ],
    "data_streams" : [
      "ilm-history-5",
      ".logs-deprecation.elasticsearch-default"
    ],
    "include_global_state" : true,
    "state" : "SUCCESS",
    "start_time" : "2022-07-19T20:40:31.955Z",
    "start_time_in_millis" : 1658263231955,
    "end_time" : "2022-07-19T20:40:33.156Z",
    "end_time_in_millis" : 1658263233156,
    "duration_in_millis" : 1201,
    "failures" : [ ],
    "shards" : {
      "total" : 4,
      "failed" : 0,
      "successful" : 4
    },
    "feature_states" : [
      {
        "feature_name" : "geoip",
        "indices" : [
          ".geoip_databases"
        ]
      }
    ]
  }
}

[root@6cd503fe970e elasticsearch-7.16.0]# ls -lh /opt/backup/
total 28K
-rw-r--r-- 1 elasticsearch elasticsearch 1.4K Jul 19 20:40 index-0
-rw-r--r-- 1 elasticsearch elasticsearch    8 Jul 19 20:40 index.latest
drwxr-xr-x 6 elasticsearch elasticsearch 4.0K Jul 19 20:40 indices
-rw-r--r-- 1 elasticsearch elasticsearch 9.6K Jul 19 20:40 meta-CG2LkKlZT_a4cPGFKiXkoA.dat
-rw-r--r-- 1 elasticsearch elasticsearch  457 Jul 19 20:40 snap-CG2LkKlZT_a4cPGFKiXkoA.dat

[root@6cd503fe970e elasticsearch-7.16.0]# curl -X DELETE "localhost:9200/test?pretty"
{
  "acknowledged" : true
}
[root@6cd503fe970e elasticsearch-7.16.0]# curl -X PUT "localhost:9200/test-2?pretty" -H 'Content-Type: application/json' -d'
> {
>   "settings": {
>     "number_of_shards": 1,
>     "number_of_replicas": 0
>   }
> }
> '
{
  "acknowledged" : true,
  "shards_acknowledged" : true,
  "index" : "test-2"
}
[root@6cd503fe970e elasticsearch-7.16.0]# curl 'localhost:9200/_cat/indices?pretty'
green open .geoip_databases r0ei1Yn9RFSVAbNbkNcjTQ 1 0 40 0 37.7mb 37.7mb
green open test-2           XMKVpy3WQsqcpnFQzTifeQ 1 0  0 0   226b   226b

_______
Для восстановления пришлось закрыть индексы
_______

[root@6cd503fe970e elasticsearch-7.16.0]# curl -X POST "localhost:9200/.ds-ilm-history-5-2022.07.19-000001/_close?pretty"
{
  "acknowledged" : true,
  "shards_acknowledged" : true,
  "indices" : {
    ".ds-ilm-history-5-2022.07.19-000001" : {
      "closed" : true
    }
  }
}
[root@6cd503fe970e elasticsearch-7.16.0]# curl -X POST "localhost:9200/.ds-.logs-deprecation.elasticsearch-default-2022.07.19-000001/_close?pretty"
{
  "acknowledged" : true,
  "shards_acknowledged" : true,
  "indices" : {
    ".ds-.logs-deprecation.elasticsearch-default-2022.07.19-000001" : {
      "closed" : true
    }
  }
}
[root@6cd503fe970e elasticsearch-7.16.0]# curl -X POST "localhost:9200/_snapshot/netology_backup/snapshot_1/_restore?pretty" -H 'Content-Type: application/json' -d'
> {
>   "indices": "*",
>   "include_global_state": true
> }
> '
{
  "accepted" : true
}
[root@6cd503fe970e elasticsearch-7.16.0]# curl 'localhost:9200/_cat/indices?pretty'
green open test-2           XMKVpy3WQsqcpnFQzTifeQ 1 0  0 0   226b   226b
green open .geoip_databases bNhlaishQwec4oncwn7kkQ 1 0 40 0 37.7mb 37.7mb
green open test             217vMpQWQ06-xMSIwszKtg 1 0  0 0   226b   226b
```
